{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "from sklearn import preprocessing\n",
    "from sklearn.externals.six import StringIO  \n",
    "from IPython.display import Image  \n",
    "from sklearn.tree import export_graphviz\n",
    "import pydotplus\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn import tree\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import ensemble\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.datasets import make_classification\n",
    "import matplotlib.pyplot as plt\n",
    "from operator import itemgetter\n",
    "from math import sqrt\n",
    "from numpy import concatenate\n",
    "from matplotlib import pyplot\n",
    "from pandas import read_csv\n",
    "from pandas import DataFrame\n",
    "from pandas import concat\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def MAPE(y_true, y_pred):\n",
    "    y = [x for x in y_true if x > 0]\n",
    "    y_pred = [y_pred[i] for i in range(len(y_true)) if y_true[i] > 0]\n",
    "    num = len(y_pred)\n",
    "    sums = 0\n",
    "    for i in range(num):\n",
    "        tmp = abs(y[i] - y_pred[i]) / y[i]\n",
    "        sums += tmp\n",
    "    mape = sums * (100 / num)\n",
    "    return mape\n",
    "\n",
    "import math\n",
    "def eva_regress(y_true, y_pred):\n",
    "    mape = MAPE(y_true, y_pred)\n",
    "    vs = metrics.explained_variance_score(y_true, y_pred)\n",
    "    mae = metrics.mean_absolute_error(y_true, y_pred)\n",
    "    mse = metrics.mean_squared_error(y_true, y_pred)\n",
    "    r2 = metrics.r2_score(y_true, y_pred)\n",
    "    print('explained_variance_score:%f' % vs)\n",
    "    print('mape:%f%%' % mape)\n",
    "    print('mae:%f' % mae)\n",
    "    print('mse:%f' % mse)\n",
    "    print('rmse:%f' % math.sqrt(mse))\n",
    "    print('r2:%f' % r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correlations = pd.read_csv('../../DCP-HTO/calculated_correlation/correlation_current.csv')\n",
    "correlations = correlations.drop('Unnamed: 0',axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hot_outliers(df,k):\n",
    "    intersections = df.columns\n",
    "    odf = pd.DataFrame()\n",
    "    for intersection in intersections:\n",
    "        y = df[intersection]\n",
    "        boundary = y.sort_values().head(k)[-1]#Get K lowest LOF score and use as boundary \n",
    "        print('Boundary is set to: ', boundary)\n",
    "        odf['ol_'+intersection] = y.apply(make_binary,boundary=boundary)\n",
    "    return odf\n",
    "    \n",
    "#Make the label a binary of outlier or not.\n",
    "def make_binary(row,boundary):\n",
    "    if row <= boundary:\n",
    "        row = 1\n",
    "    else:\n",
    "        row = 0\n",
    "    return row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tflow_file = '../../DCP-HTO/SFPD-LOF/input_data/other_intersections/'\n",
    "tflow = pd.read_csv(tflow_file+'K302.csv',index_col=[\"timestamp\"], parse_dates=True)\n",
    "#sel = ['K173','K414','K158','K402','K305']\n",
    "sel = [\n",
    "    'K173','K414','K158','K402','K305',\n",
    "    'K071','K097','K124','K128','K159','K184','K189','K206','K225','K270','K304','K405','K406','K424','K430','K703','K704','K707','K711','K561','K504','K145','K250',\n",
    "    'a12in','a12out','n211in','n211out','n141in','n141out','n142in','n142out','n143in','n143out'\n",
    "]\n",
    "for i in sel:\n",
    "    #print(i)\n",
    "    x = pd.read_csv(tflow_file+i+'.csv',index_col=[\"timestamp\"], parse_dates=True)\n",
    "    tflow = pd.merge(tflow, x, on='timestamp',how='left')\n",
    "\n",
    "\n",
    "#for f in filenames:\n",
    " #   dataframes.append(pd.read_csv(f))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tflow = tflow.fillna(method='ffill')\n",
    "tflow = tflow.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tflow.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tflow.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# All intersection data!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert series to supervised learning\n",
    "def series_to_supervised(data, n_in=1, n_out=1, dropnan=True):\n",
    "\tn_vars = 1 if type(data) is list else data.shape[1]\n",
    "\tdf = DataFrame(data)\n",
    "\tcols, names = list(), list()\n",
    "\t# input sequence (t-n, ... t-1)\n",
    "\tfor i in range(n_in, 0, -1):\n",
    "\t\tcols.append(df.shift(i))\n",
    "\t\tnames += [('var%d(t-%d)' % (j+1, i)) for j in range(n_vars)]\n",
    "\t# forecast sequence (t, t+1, ... t+n)\n",
    "\tfor i in range(0, n_out):\n",
    "\t\tcols.append(df.shift(-i))\n",
    "\t\tif i == 0:\n",
    "\t\t\tnames += [('var%d(t)' % (j+1)) for j in range(n_vars)]\n",
    "\t\telse:\n",
    "\t\t\tnames += [('var%d(t+%d)' % (j+1, i)) for j in range(n_vars)]\n",
    "\t# put it all together\n",
    "\tagg = concat(cols, axis=1)\n",
    "\tagg.columns = names\n",
    "\t# drop rows with NaN values\n",
    "\tif dropnan:\n",
    "\t\tagg.dropna(inplace=True)\n",
    "\treturn agg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load dataset\n",
    "#dataset = read_csv('https://raw.githubusercontent.com/jbrownlee/Datasets/master/pollution.csv', header=0,index_col=0)\n",
    "values = tflow.values\n",
    "values = values.astype('float32')\n",
    "\n",
    "# normalize features\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "scaled = scaler.fit_transform(values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# specify the number of lag hours\n",
    "n_hours = 12\n",
    "n_features = 41\n",
    "\n",
    "# frame as supervised learning\n",
    "reframed = series_to_supervised(scaled, n_hours, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split into train and test sets\n",
    "values = reframed.values\n",
    "n_train_hours = 140256\n",
    "train = values[:n_train_hours, :]\n",
    "test = values[n_train_hours:, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split into input and outputs\n",
    "n_obs = n_hours * n_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X, train_y = train[:, :n_obs], train[:, -n_features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_X, test_y = test[:, :n_obs], test[:, -n_features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reshape input to be 3D [samples, timesteps, features]\n",
    "train_X = train_X.reshape((train_X.shape[0], n_hours, n_features))\n",
    "test_X = test_X.reshape((test_X.shape[0], n_hours, n_features))\n",
    "print(train_X.shape, train_y.shape, test_X.shape, test_y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# design network\n",
    "model = Sequential()\n",
    "model.add(LSTM(50, input_shape=(train_X.shape[1], train_X.shape[2])))\n",
    "model.add(Dense(1))\n",
    "model.compile(loss='mae', optimizer='adam')\n",
    "# fit network\n",
    "history = model.fit(train_X, train_y, epochs=50, batch_size=72, validation_data=(test_X, test_y), verbose=2, shuffle=False)\n",
    "# plot history\n",
    "pyplot.plot(history.history['loss'], label='train')\n",
    "pyplot.plot(history.history['val_loss'], label='test')\n",
    "pyplot.legend()\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make a prediction\n",
    "yhat = model.predict(test_X)\n",
    "test_X = test_X.reshape((test_X.shape[0], n_hours*n_features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# invert scaling for forecast\n",
    "old_inv_yhat = concatenate((yhat, test_X[:, -40:]), axis=1)\n",
    "old_inv_yhat = scaler.inverse_transform(old_inv_yhat)\n",
    "old_inv_yhat = old_inv_yhat[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# invert scaling for actual\n",
    "test_y = test_y.reshape((len(test_y), 1))\n",
    "inv_y = concatenate((test_y, test_X[:, -40:]), axis=1)\n",
    "inv_y = scaler.inverse_transform(inv_y)\n",
    "inv_y = inv_y[:,0]\n",
    "# calculate RMSE\n",
    "rmse = sqrt(mean_squared_error(inv_y, old_inv_yhat))\n",
    "print('Test RMSE: %.3f' % rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eva_regress(inv_y, old_inv_yhat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = {'LSTM':old_inv_yhat[:300],'True data':inv_y[:300]}\n",
    "df = pd.DataFrame(data=df)\n",
    "#df = df.set_index('datetime')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(inv_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Advanced input data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Selection based on dynamic feature reduction\n",
    "sel=['K302',\n",
    " 'K173',\n",
    " 'K414',\n",
    " 'K158',\n",
    " 'K402',\n",
    " 'K305',\n",
    " 'K128',\n",
    " 'K184',\n",
    " 'K206',\n",
    " 'K225',\n",
    " 'K304',\n",
    " 'K406',\n",
    " 'K704',\n",
    " 'K711',\n",
    " 'K561',\n",
    " 'K504',\n",
    " 'K145',\n",
    " 'a12in',\n",
    " 'a12out',\n",
    " 'n211out',\n",
    " 'n141in',\n",
    " 'n141out',\n",
    " 'n142in',\n",
    " 'n143out'\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fpd = pd.read_csv('../../DCP-HTO/dataframe_creation/complete_dataframe.csv',index_col=0, parse_dates=True)\n",
    "fpd = fpd.fillna(1)\n",
    "fpd_sel = fpd[sel]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "odf = one_hot_outliers(fpd_sel,50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rodf = odf.resample('15T').pad()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rodf.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rodf.index.name = 'timestamp'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tflow_file = '../../DCP-HTO/SFPD-LOF/input_data/other_intersections/'\n",
    "tflow = pd.read_csv(tflow_file+'K302.csv',index_col=[\"timestamp\"], parse_dates=True)\n",
    "for i in sel:\n",
    "    #print(i)\n",
    "    x = pd.read_csv(tflow_file+i+'.csv',index_col=[\"timestamp\"], parse_dates=True)\n",
    "    tflow = pd.merge(tflow, x, on='timestamp',how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tflow = tflow.drop(columns=['Unnamed: 0_x','Unnamed: 0_y'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tflow = pd.merge(tflow, rodf, on='timestamp',how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tflow = tflow.fillna(method='ffill')\n",
    "tflow = tflow.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dti = tflow['K414']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dti = dti[140256:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert series to supervised learning\n",
    "def series_to_supervised(data, n_in=1, n_out=1, dropnan=True):\n",
    "    n_vars = 1 if type(data) is list else data.shape[1]\n",
    "    df = DataFrame(data)\n",
    "    cols, names = list(), list()\n",
    "    # input sequence (t-n, ... t-1)\n",
    "    for i in range(n_in, 0, -1):\n",
    "        cols.append(df.shift(i))\n",
    "        names += [('var%d(t-%d)' % (j+1, i)) for j in range(n_vars)]\n",
    "    # forecast sequence (t, t+1, ... t+n)\n",
    "    for i in range(0, n_out):\n",
    "        cols.append(df.shift(-i))\n",
    "        if i == 0:\n",
    "            names += [('var%d(t)' % (j+1)) for j in range(n_vars)]\n",
    "        else:\n",
    "            names += [('var%d(t+%d)' % (j+1, i)) for j in range(n_vars)]\n",
    "    # put it all together\n",
    "    agg = concat(cols, axis=1)\n",
    "    agg.columns = names\n",
    "    # drop rows with NaN values\n",
    "    if dropnan:\n",
    "        agg.dropna(inplace=True)\n",
    "    return agg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "values = tflow.values\n",
    "values = values.astype('float32')\n",
    "\n",
    "# normalize features\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "scaled = scaler.fit_transform(values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# specify the number of lag hours\n",
    "n_hours = 12\n",
    "n_features =49\n",
    "\n",
    "# frame as supervised learning\n",
    "reframed = series_to_supervised(scaled, n_hours, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split into train and test sets\n",
    "values = reframed.values\n",
    "n_train_hours = 140256\n",
    "train = values[:n_train_hours, :]\n",
    "test = values[n_train_hours:, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split into input and outputs\n",
    "n_obs = n_hours * n_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X, train_y = train[:, :n_obs], train[:, -n_features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_X, test_y = test[:, :n_obs], test[:, -n_features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reshape input to be 3D [samples, timesteps, features]\n",
    "train_X = train_X.reshape((train_X.shape[0], n_hours, n_features))\n",
    "test_X = test_X.reshape((test_X.shape[0], n_hours, n_features))\n",
    "print(train_X.shape, train_y.shape, test_X.shape, test_y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# design network\n",
    "model = Sequential()\n",
    "model.add(LSTM(50, input_shape=(train_X.shape[1], train_X.shape[2])))\n",
    "model.add(Dense(1))\n",
    "model.compile(loss='mae', optimizer='adam')\n",
    "# fit network\n",
    "history = model.fit(train_X, train_y, epochs=50, batch_size=72, validation_data=(test_X, test_y), verbose=2, shuffle=False)\n",
    "# plot history\n",
    "pyplot.plot(history.history['loss'], label='train')\n",
    "pyplot.plot(history.history['val_loss'], label='test')\n",
    "pyplot.legend()\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make a prediction\n",
    "yhat = model.predict(test_X)\n",
    "test_X = test_X.reshape((test_X.shape[0], n_hours*n_features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# invert scaling for forecast\n",
    "inv_yhat = concatenate((yhat, test_X[:, -48:]), axis=1)\n",
    "\n",
    "inv_yhat = scaler.inverse_transform(inv_yhat)\n",
    "inv_yhat = inv_yhat[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# invert scaling for actual\n",
    "test_y = test_y.reshape((len(test_y), 1))\n",
    "inv_y = concatenate((test_y, test_X[:, -48:]), axis=1)\n",
    "inv_y = scaler.inverse_transform(inv_y)\n",
    "inv_y = inv_y[:,0]\n",
    "# calculate RMSE\n",
    "rmse = sqrt(mean_squared_error(inv_y, inv_yhat))\n",
    "print('Test RMSE: %.3f' % rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eva_regress(inv_y, inv_yhat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = {'LSTM':inv_yhat[:300],'True data':inv_y[:300]}\n",
    "df = pd.DataFrame(data=df)\n",
    "#df = df.set_index('datetime')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.plot(y=['LSTM','True data'],figsize=(20,10),title='Traffic flow outlier predictions')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ndti = dti[496:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ndf = {'LSTM':inv_yhat[484:],'True data':inv_y[484:],'datetime':ndti.index}\n",
    "ndf = pd.DataFrame(data=ndf)\n",
    "ndf = ndf.set_index('datetime')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Outlier zoom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k302 = pd.read_csv('../dat/traffic_intersection_selection.csv', index_col=[\"timestamp\"], usecols=[\"timestamp\",\"K414\"], parse_dates=True)\n",
    "testol = k302['2019':]\n",
    "testolindex = testol.sort_values('K414').head(10).index\n",
    "strdatetimes = [str(a) for a in testolindex]\n",
    "sliced = []\n",
    "for item in strdatetimes:\n",
    "    sliced.append(item[:13]+':00:00')\n",
    "    sliced.append(item[:13]+':15:00')\n",
    "    sliced.append(item[:13]+':30:00')\n",
    "    sliced.append(item[:13]+':45:00')\n",
    "test_dat = pd.read_csv('../TFP_adapted/data/new_test.csv',parse_dates=['timestamp'])\n",
    "olindexes = test_dat[test_dat.timestamp.isin(sliced)].index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "andf = ndf[ndf.index.isin(sliced)]\n",
    "def get_diff(row):\n",
    "    return row['True data'] - row ['LSTM']\n",
    "andf['diff'] = andf.apply(get_diff,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#andf = andf.sort_values('diff',ascending=False)[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#andf = andf.drop('diff',axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eva_regress(andf['True data'], andf['LSTM'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "andf.plot(kind='bar',figsize=(20,10),title='Advanced traffic flow outlier predictions')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OLD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "old_ndf = {'LSTM':old_inv_yhat[4068:],'True data':inv_y[484:],'datetime':ndti.index}\n",
    "old_ndf = pd.DataFrame(data=old_ndf)\n",
    "old_ndf = old_ndf.set_index('datetime')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k302 = pd.read_csv('../dat/traffic_intersection_selection.csv', index_col=[\"timestamp\"], usecols=[\"timestamp\",\"K414\"], parse_dates=True)\n",
    "testol = k302['2019':]\n",
    "testolindex = testol.sort_values('K414').head(10).index\n",
    "strdatetimes = [str(a) for a in testolindex]\n",
    "sliced = []\n",
    "for item in strdatetimes:\n",
    "    sliced.append(item[:13]+':00:00')\n",
    "    sliced.append(item[:13]+':15:00')\n",
    "    sliced.append(item[:13]+':30:00')\n",
    "    sliced.append(item[:13]+':45:00')\n",
    "test_dat = pd.read_csv('../TFP_adapted/data/new_test.csv',parse_dates=['timestamp'])\n",
    "olindexes = test_dat[test_dat.timestamp.isin(sliced)].index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bandf = old_ndf[old_ndf.index.isin(sliced)]\n",
    "def get_diff(row):\n",
    "    return row['True data'] - row ['LSTM']\n",
    "bandf['diff'] = bandf.apply(get_diff,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#bandf = bandf.sort_values('diff',ascending=False)[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "old_diff = bandf['diff']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bandf = bandf.drop('diff',axis=1)\n",
    "bandf = bandf.sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eva_regress(bandf['True data'], bandf['LSTM'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "bandf.plot(kind='bar',figsize=(20,10),title='Naive traffic flow outlier predictions')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib as mpl\n",
    "def plot_results(y_true, y_preds, names):\n",
    "    \"\"\"Plot\n",
    "    Plot the true data and predicted data.\n",
    "\n",
    "    # Arguments\n",
    "        y_true: List/ndarray, ture data.\n",
    "        y_pred: List/ndarray, predicted data.\n",
    "        names: List, Method names.\n",
    "    \"\"\"\n",
    "    d = '2020-1-4 00:00'\n",
    "    x = pd.date_range(d, periods=len(y_true), freq='15min')\n",
    "\n",
    "    fig = plt.figure()\n",
    "    ax = fig.add_subplot(111)\n",
    "    \n",
    "    ax.plot(x, y_preds[0], label=names[0],color='#ff7f0e')\n",
    "    ax.plot(x, y_true, label='True Data',color='#1f77b4')\n",
    "        \n",
    "\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.xlabel('Time of Day')\n",
    "    plt.ylabel('Flow')\n",
    "\n",
    "    date_format = mpl.dates.DateFormatter(\"%d-%m %H:%M\")\n",
    "    ax.xaxis.set_major_formatter(date_format)\n",
    "    fig.autofmt_xdate()\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plot_pred = [old_ndf['LSTM'][300:600]]\n",
    "plot_true = old_ndf['True data'][300:600]\n",
    "plot_results(plot_true,plot_pred,['Multivariate LSTM'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Combined plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "naive_pred = bandf.LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "andf['naive'] = naive_pred\n",
    "andf['old_diff'] = old_diff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "andf[['LSTM','True data','naive']].plot(kind='bar',figsize=(20,10),title='Naive traffic flow outlier predictions')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hourly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nandf = andf.resample('H').first()\n",
    "nandf = nandf[nandf.LSTM >0]\n",
    "#nandf = nandf.drop('diff',axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del nandf.index.name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nandf = nandf.rename(columns={\"naive\": \"Multivariate LSTM\"})\n",
    "nandf = nandf.rename(columns={\"LSTM\": \"OE-LSTM\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_ind = nandf.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_ind = []\n",
    "for item in temp_ind:\n",
    "    new_ind.append(str(item)[5:-3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nandf.index = new_ind"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nandf[['Multivariate LSTM','True data','OE-LSTM']].plot(kind='bar',figsize=(10,5),fontsize=10,color=['#ff7f0e','#1f77b4','#2ca02c'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#nandf[['diff','old_diff']].abs().plot(kind='bar',figsize=(20,10),title='Advanced traffic flow outlier predictions')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mapes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mape_dat = {'Naive LSTM':[12.18,31.09],'OE-LSTM':[10.91,16.87]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mape_df = pd.DataFrame(mape_dat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mape_df.index = ['All test data','Top outliers']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "color_dict = {'Naive LSTM': '#1f77b4', 'OE-LSTM': '#2ca02c'}\n",
    "\n",
    "# use get to specify dark gray as the default color.\n",
    "mape_df.plot(kind='bar',title='MAPE comparison',color=['#ff7f0e','#2ca02c'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
